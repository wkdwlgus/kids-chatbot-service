import os
import pandas as pd
import numpy as np
import chromadb
from chromadb.config import Settings as ChromaSettings
from dotenv import load_dotenv
from time import sleep
import openai

# ============================================
# í™˜ê²½ë³€ìˆ˜
# ============================================
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ============================================
# ì„¤ì •
# ============================================
CHROMA_HOST = "localhost"
CHROMA_PORT = 8000
COLLECTION_NAME = "kid_program_collection"

CSV_PATH = "./rag_data_integrated_final_rev_loc.csv"

# OpenAI ì„ë² ë”© ëª¨ë¸ ì„ íƒ
EMB_MODEL = "text-embedding-3-large"    # 3072ì°¨ì› (ì¶”ì²œ)
# EMB_MODEL = "text-embedding-3-small"  # 1536ì°¨ì› (ë¹„ìš©â†“)

print("="*70)
print("ğŸ”¥ Kids Program RAG - ChromaDB ë²¡í„° ë°ì´í„° ì—…ë¡œë“œ")
print("="*70)
print(f"ğŸ“ CSV: {CSV_PATH}")
print(f"ğŸ”Œ ChromaDB: {CHROMA_HOST}:{CHROMA_PORT}")
print(f"ğŸ“š ì»¬ë ‰ì…˜: {COLLECTION_NAME}")
print("="*70)

# ============================================
# 1. íŒŒì¼ í™•ì¸
# ============================================
if not os.path.exists(CSV_PATH):
    raise SystemExit(f"âŒ CSV íŒŒì¼ ì—†ìŒ: {CSV_PATH}")

print("âœ… CSV íŒŒì¼ í™•ì¸ ì™„ë£Œ")

# ============================================
# 2. CSV ë¡œë“œ
# ============================================
print("\nğŸ“¥ CSV ë¡œë“œ ì¤‘...")
df = pd.read_csv(CSV_PATH).fillna("")
print(f"âœ… ì´ {len(df)}ê°œ í–‰ ë¡œë“œ ì™„ë£Œ")

# ============================================
# 3. ë¬¸ì„œ(document) ìƒì„± í•¨ìˆ˜ (ì„ë² ë”© ë‚´ìš©)
# ============================================
def build_doc(row):
    parts = []

    # 1) ì‹œì„¤ëª…
    if row.get("Name"):
        parts.append(f"ì‹œì„¤ëª…: {row['Name']}")

    # 2) ë¶„ë¥˜ Category1~3
    cats = [row.get("Category1",""), row.get("Category2",""), row.get("Category3","")]
    cats = [c for c in cats if c]
    if cats:
        parts.append("ë¶„ë¥˜: " + ", ".join(cats))

    # 3) í–‰ì •ë™/ì‹œêµ°êµ¬
    if row.get("CTPRVN_NM") or row.get("SIGNGU_NM"):
        parts.append(f"ì§€ì—­: {row['CTPRVN_NM']} {row['SIGNGU_NM']}")

    # 4) ì£¼ì†Œ
    if row.get("Address"):
        parts.append(f"ì£¼ì†Œ: {row['Address']}")

    # 5) ìš´ì˜ì‹œê°„
    if row.get("Time"):
        parts.append(f"ìš´ì˜ì‹œê°„: {row['Time']}")

    # 6) ìš´ì˜ìš”ì¼
    if row.get("Day"):
        parts.append(f"ìš´ì˜ìš”ì¼: {row['Day']}")

    # 7) ë¹„ìš©
    if row.get("Cost"):
        parts.append(f"ì´ìš©ìš”ê¸ˆ: {row['Cost']}")

    # 8) ì‹¤ë‚´/ì‹¤ì™¸
    if row.get("in_out"):
        parts.append(f"ì‹œì„¤ í˜•íƒœ: {row['in_out']}")

    # 9) ê¶Œì¥ì—°ë ¹ (ìì—°ì–´ë¡œ ì˜ë¯¸ ìˆìœ¼ë¯€ë¡œ í¬í•¨)
    if row.get("Age"):
        parts.append(f"ê¶Œì¥ì—°ë ¹: {row['Age']}")

    # 10) ììœ  í…ìŠ¤íŠ¸ Note
    if row.get("Note"):
        parts.append(f"ì¶”ê°€ì„¤ëª…: {row['Note']}")

    return ". ".join(parts)

print("\nğŸ“ ë¬¸ì„œ ìƒì„± ì¤‘...")
documents = df.apply(build_doc, axis=1).tolist()
print(f"âœ… ë¬¸ì„œ {len(documents)}ê°œ ìƒì„±")

# ============================================
# 4. ë©”íƒ€ë°ì´í„° êµ¬ì„± (í•„í„°ë§/ì •ë ¬ìš©)
# ============================================
META_COLS = [
    "Name", "Category1", "Category2", "Category3",
    "Address", "CTPRVN_NM", "SIGNGU_NM",
    "LAT", "LON", "in_out",
    "Age", "age_min", "age_max",
    "Time", "Day", "Cost",
    "Note"
]

META_COLS = [c for c in META_COLS if c in df.columns]
metadatas = df[META_COLS].to_dict(orient="records")

ids = [f"doc_{i}" for i in range(len(df))]

print(f"ğŸ“‹ ë©”íƒ€ë°ì´í„° ì»¬ëŸ¼: {META_COLS}")

# ============================================
# 5. ChromaDB ì—°ê²°
# ============================================
print("\nğŸ”Œ ChromaDB ì—°ê²° ì¤‘...")
client = chromadb.HttpClient(
    host=CHROMA_HOST,
    port=CHROMA_PORT,
    settings=ChromaSettings(anonymized_telemetry=False)
)
print("âœ… ì—°ê²° ì„±ê³µ!")

# ê¸°ì¡´ ì»¬ë ‰ì…˜ ì‚­ì œ
existing = [c.name for c in client.list_collections()]
if COLLECTION_NAME in existing:
    print(f"ğŸ—‘ ê¸°ì¡´ ì»¬ë ‰ì…˜ '{COLLECTION_NAME}' ì‚­ì œ ì¤‘...")
    client.delete_collection(COLLECTION_NAME)
    sleep(1)
    print("   â†’ ì‚­ì œ ì™„ë£Œ")

# ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±
print(f"ğŸ“š ìƒˆ ì»¬ë ‰ì…˜ ìƒì„±: {COLLECTION_NAME}")
collection = client.create_collection(COLLECTION_NAME)

# ============================================
# 6. OpenAI ì„ë² ë”© + ë°ì´í„° ì‚½ì…
# ============================================
print("\nğŸš€ ë²¡í„° ì„ë² ë”© + Chroma ì—…ë¡œë“œ ì‹œì‘")

BATCH = 100
total = len(documents)

for start in range(0, total, BATCH):
    end = min(start + BATCH, total)
    
    batch_docs = documents[start:end]

    # ---- OpenAI Embedding í˜¸ì¶œ ----
    try:
        res = openai.embeddings.create(
            model=EMB_MODEL,
            input=batch_docs
        )
    except Exception as e:
        print(f"âŒ OpenAI ì—ëŸ¬ ë°œìƒ: {e}")
        sleep(2)
        continue

    embeddings = [item.embedding for item in res.data]

    # ---- Chroma ì—…ë¡œë“œ ----
    collection.add(
        ids=ids[start:end],
        documents=batch_docs,
        metadatas=metadatas[start:end],
        embeddings=embeddings
    )

    print(f"   â†’ {end}/{total} ({(end/total)*100:.1f}%) ì™„ë£Œ")

    sleep(0.3)  # Rate-limit ì™„í™”

print("\nğŸ‰ ëª¨ë“  ë°ì´í„° ì—…ë¡œë“œ ì™„ë£Œ!")

# ============================================
# 7. ìƒ˜í”Œ ì¡°íšŒ (ë¬¸ì„œ + ë©”íƒ€ë°ì´í„°)
# ============================================
print("\nğŸ” ìƒ˜í”Œ ë¬¸ì„œ/ë©”íƒ€ë°ì´í„° ì¶œë ¥")

sample = collection.get(limit=3, include=["documents", "metadatas"])

for idx in range(len(sample["documents"])):
    print("\n-----------------------------------")
    print(f"[{idx+1}] ë¬¸ì„œ:")
    print(sample["documents"][idx])
    print("\në©”íƒ€ë°ì´í„°:")
    print(sample["metadatas"][idx])

print("\n" + "="*70)
print("ğŸ‰ ChromaDB ì„ë² ë”© ì—…ë¡œë“œ ì™„ë£Œ!")
print(f"ğŸ“š ì»¬ë ‰ì…˜ ì´ë¦„: {COLLECTION_NAME}")
print(f"ğŸ“Œ ì´ ë¬¸ì„œ ìˆ˜: {collection.count()}")
print("="*70)
